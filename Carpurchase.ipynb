{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3638d76-cf85-4bdf-aa0b-00135a524188",
   "metadata": {},
   "source": [
    "#### We are going to develop a machine learning model to predict the total dollar amount that customers are willing to pay while purchasing a car given the following attributes:\n",
    "\n",
    "##### Customer Name\n",
    "##### Customer Email\n",
    "##### Country\n",
    "##### Gender\n",
    "##### Age\n",
    "##### Annual Salary\n",
    "##### Credit Card Debt \n",
    "##### Net Worth\n",
    "\n",
    "#### The Model should Predict Car Purchase Amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0575f4-065d-4549-b511-ba5d860a1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f12e2-a468-48f5-b5b1-1afce1951631",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87193c-2ff1-4e11-9c04-dfb18131df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868633e-4409-44c3-9158-2130db5538ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Car_Purchasing_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0339be-d4e7-4d20-83e5-46d7ad185686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9a320-cd52-4084-ae80-0e9d40fbf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36441d68-04a8-42c3-8fa1-24b1e14a05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of rows is',df.shape[0])\n",
    "print('number of columns is',df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3de505-628f-4847-b3f4-cae900e24427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffaa3e3-accc-4def-8e57-1d5948189960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3807707-f4a4-49ab-b30a-0a6f43e76ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3663f-4680-4d15-b2ae-eb6fd95cc93c",
   "metadata": {},
   "source": [
    "#### Let us do some visualizations to know relationships between our variables using seaborns pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c47ed3-10c9-44d4-b782-08591617c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4f767-fc35-4316-af95-02eb5ac29fc8",
   "metadata": {},
   "source": [
    "##### We can use pairplot to plot multiple pairwise bivariate dstributions in our data sets. Looking at our target variable(Car Purchase Amount) in the pairplots,we can see that Age,Annual Salary,and Networth increase with increase in purchase amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fbdbcf-83ab-42f2-952f-c9abdaf983a7",
   "metadata": {},
   "source": [
    "##### Let us drop irrelevant features and store our independent variables into matrix X and dependent variables into vector y.We are  going to drop Custmer name ,Custoer Email and Country because they have no effect on our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954f9de-b626-46a6-86b6-a3f7ee0f58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d7970-a22b-499b-8b7c-f2b1a9668d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Customer Name', 'Customer e-mail', 'Country','Car Purchase Amount'],axis=1)\n",
    "y=df['Car Purchase Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367795fb-3652-4f18-ac09-5848a25d9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605098fe-0bd2-45e4-a76c-061c81fb3ec8",
   "metadata": {},
   "source": [
    "##### So,with a few line of codes,we have reved irrelevant variables and also stored our independent and dependent variables in Matrix X and vector y respectively\n",
    "##### Let us perform feature scaling(Normalization).What is Normalization?\n",
    "##### Normalization is a scaling technique in which values are rescale so that they end up ranging between 0 and 1.We will make use of minmaxscalar on our independent variables X firstly,then later on our target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98324d-6c87-4e63-b794-4222391588ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2101a0d4-22c6-4b56-ae68-fc024c261ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_scaled=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9e7e8-3ed7-4f15-a3d2-cf38332add3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae9191-e205-4a9c-99d9-f72dbe66139e",
   "metadata": {},
   "source": [
    "##### Now our independent variables are scaled between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f0c30-0578-45dd-9ef1-319761c8b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = MinMaxScaler()\n",
    "y_reshape = y.values.reshape(-1,1)\n",
    "y_scaled=sc1.fit_transform(y_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480baf2-fd28-43b6-a7a3-07543cf904ea",
   "metadata": {},
   "source": [
    "##### We had to reshape our data using numpy reshape methods into (-1,1).That is why we created a y_reshaped variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f118799-7f01-463a-bae1-3032150db23c",
   "metadata": {},
   "source": [
    "#### It is Time to split our datasets into training sets and testing sets to evauate the performance of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f873d6-3bb3-4b1e-a0e6-d4934f861f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffe59e-cbbd-4f01-8c39-90809efd0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y_scaled,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0092316-593f-45f7-a1d9-3d41dd019923",
   "metadata": {},
   "source": [
    "#### We are going to train our model on X_train and y_train and perform prediction using X_test(our unseen samples),and we will compare predicted results by our models with y_test.\n",
    "#### Looking at our datasets,our target variable,there are continuous values so this automatically becomes a regression problem!.\n",
    "#### Now let's import our different regression models and train them using fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decdabde-e9a2-434f-af60-cc7f9b868c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4627e49-14e1-4cc0-9d6d-f491317e8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "svm = SVR()\n",
    "svm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train,y_train)\n",
    "\n",
    "xg = XGBRegressor()\n",
    "xg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704e876-be77-4196-be0c-e0cac87e6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2f96a-bb17-42c9-867c-75e474780e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fc0a0-cf35-4f8b-adc7-e64915e05be2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
